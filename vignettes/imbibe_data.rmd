---
title: "<img src=\"../img/ipayipi_120.png\" width=\"20%\" height=\"20%\" style=\"float: right;\"/> <br/> <br/>  ipayipi: <br/> <br/> opening the pipeline---imbibe data"
output: rmarkdown::html_vignette
date: "`r format(Sys.time(), '%d %B, %Y')`"
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{ipayipi---opening the pipeline---imbibe data}
  %\VignetteEncoding{UTF-8}
---


```{r setup, echo=FALSE, results="hide"}
defaultW <- getOption("warn") 
options(warn = -1)

packages <- c("ipayipi")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
    install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
options(warn = defaultW)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/home/paulg/Documents/projects_current/ipayipi_data_pipe/')
```

```{r check-wd, eval=TRUE, echo=TRUE}
getwd()
```

# Summary

Introduction to batch-data processing of time-series data using R __ipayipi__.

1. Install `R ipayipi` from [GitHub](https://github.com/SAEONData/ipayipi),
1. Initiate pipeline,
1. Imbibe data,
1. Standardise data,
6. 



# Introduction

Organising time-series data from loggers, such as, weather stations or ground-water sensors, requires no small amount of data structuring. ipayipi helps make this process dynamic and structured, so that, processing, down (and back up) a pipeline, is traceable. Importantly, ipayipi preserves raw-data integrity and initiates archival---so raw data is available in a standardised format---and the processing of this data can be updated.

The package is maintained [GitHub](https://github.com/SAEONData/ipayipi) and can be installed using the 'devtools' package: `devtools::install_github("SAEONData/ipayipi")`.

# Initiate pipeline: the 'pipe_house'

The 'pipe_house' is the name of the directory where we will initiate a data-pipeline structure. To keep things simple, we will _only_ use our 'pipe_house' for defined data streams. In this vignette the data stream consists of meteorological data gathered from weather stations. 'ipayipi' handles most time-series data readable from flat files into R. Data for this vignette can be downloaded from GitHub in the package's raw-data folder [here]().

```{r, pipe_house}
# first load ipayipi after installation
library(ipayipi)

# define our general working directory: wherever data is going to be processed ...
wd <- "ipayipi/data-raw/eg_data/met_eg"

# define directory from which data will be sourced
sd <- "ipayipi/data-raw/eg_data/met_eg/dta_in"

# set up pipeline directory structure
pipe_house <- ipip_init(work_dir = wd, source_dir = sd)


print(pipe_house)
```

What has `ipip_init()` done? Creates the following directories:

1. 'source_dir': where new logger data is going to be made available.
2. 'wait_room': waiting room for imbibing data into the pipeline.
3. 'nomvet_room': where standardised/corrected logger files get archived.
4. 'ipip_room': here data get appended into contiguous single station records, and processed.
5. 'raw_room': where 'unaltered' raw data gets pushed.

_Running this function will not overwrite existing data_.

# Imbibe data

Data is extracted from the pipelines data source, that is, the 'source directory' (`pipe_house$source_dir`), and extracted into the 'waiting room' (`pipe_house$wait_room`) with two functions. The example data contains two-years of Cambell Scientific logger text files derived from sensors on a [SAEON](https://www.saeon.ac.za) meteorological station in northern Maputaland, South Africa.

```{r, import-imbibe}
# copy data from source to the wait_room
logger_data_import_batch(pipe_house = pipe_house,
  file_ext = ".dat", # the file extension (with period) of raw data files
  verbose = FALSE # if set to two some progress will be reported
)
```

Now that some data is in the 'wait_room' directory we can read it into R. Note the preset 'data_setup' option for Cambell Scientific TOA5 formatted files.

```{r, imbibe}
imbibe_raw_batch(pipe_house = pipe_house,
  file_ext_in = ".dat", # file extension of 'raw' data files
  col_dlm = ",",        # column delimeter (change to match 'raw' format)
  data_setup = ipayipi::cs_toa5, # standard for reading t0a5 formatted files 
  record_interval_type = "continuous"
)
```
Data input formats, that is, the 'data_setup' can be customised following the help files of the `imbibe_raw_logger_dt()` function (i.e., `?imbibe_raw_logger_dt`). In addition, there are other customisable options such as date-time formats and time zones.

Record interval type is an important paramenter. ipayipi handles continuous, event-based (discontinuous), and mixed time-series data types. Record intervals of data are evaluated using the ipayipi's function, `record_interval_eval()`. Data with 'mixed' time-series types get automatically separated out---only 'like' types will be appended into formal station records. 

# Standardise data

Both file-header information plus other phenomena (variable) metadata will now be standardised. Owing to changes in spelling/synonyms file names and associated header nomenclature has to be scrutinised first.

```{r, nom standard, eval = FALSE}
header_sts(pipe_house)
```

Note that on the first-time running `header_sts()` in a pipe-house directory a warning will be produced. This is because the user needs to define name standards. Unstandardised names (or columns) have the preffix 'uz'. These standards get stored in a file called 'nomtab.rns' in the 'waiting room'. If this file is deleted---a new one will be generated---but the user will have to populate the tables with synonym vocab.

The nomenclature table in the 'waiting room' can be updated from 'csv' format (or directly in R). If a new synonym gets introduced: further data processing is not possible, and a 'csv' version of the 'nomtab.rns' will be copied to the 'waiting room'. Edit this file and read it back into the pipeline.

Only the following fields require editing in the 'nomtab' 'csv':

- location: standardised location shorthand,
- station: standardised station name,
- standard title: station name. Generally a concatenation of location and station.
- table name: shorthand description of the data table from respective logger. For Cambell Scientific loggers this should be a description of the time interval between recordings.

Once `NA` values of the above fields have been populated (remember don't edit corresponding unstandardised/uz fields) the edited csv can be read using:

`read_nomtab_csv(pipe_house)`

This function will search for the most recently updated 'csv' nomenclature table and update the 'nomtab.rns'. Once again a check will be run during this process ensuring that `NA` values for the above four fields have been populated. If this update is successful rerun `header_sts(pipe_house)` to standardise the imbibed data in the 'waiting room'.

In step with good [tidy data](https://www.tidyr.tidyverse.org/articles/tidy-data.html) standards, keep nomenclature etc to 'snake case' with no special characters (bar the useful underscore').
'
In order to standardise _phenomena_ metadata run this ... similarly to the header data standardisation a 'phenomena table' ('phentab.rps') is produced and `NA` values need to be described. The following fields in the 'csv' phentab must be edited:

- phen_name_full: A descriptive name of the phenomenon (variable).
- phen_type: the type of phenomena (e.g., atmospheric pressure).
- phen_name: the name (used as a column header) of the phenomena. Must be created to avoid duplications.
- units: the measurement unit, e.g., bars.
- measure: describes how sampling has been done over/at the sampling interval, e.g., mean, min, sample, etc.

Additional fields that are not mandatory include:

- f_convert: A numeric multiplier that will be applied to this phenomena. Useful for converting from unstandardised to standardised units.

If an 'f_convert' factor is applied the 'uz' units must be different from the standardised units in the phenomena table. Phenomena are standardised using the `phenomena_sts()` function.

```{r, phen standard, eval = FALSE}
phenomena_sts(pipe_house)
```