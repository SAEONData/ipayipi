#' @title Build data processing pipelines
#' @description Builds a pipeline from processing _steps_ nested within pipeline _stages_. Each stage, with its respective steps, are partially evaluated by this function.
#' @param p Processing pipeline steps, each generated by `ipayipi::p_step()` parsed by `ipayipi::p_dt()`. _See examples__.
#' @param pipe_eval Logical. If TRUE then basic checks are done on the processing steps to ensure all parameters are filled and correct.
#' @details This function assists with building a tabluar representation of a data processing pipeline. The table is fully evaluated, for example, by checking station parameters and time intervals, prior to performing processing functions within `ipayipi::dt_process()`. Once fully evaluated the function parameters (`f_params`) for processing data are stored in a station file. Once stored partial evaluation is not necessary until the pipeline sequence requires updating.
#' @return Data processing pipeline in the format of a `data.table` of class "pipe_seq".
#' @examples
#' ## generate a basic processing pipeline
#'
#' # first harvest data
#' # note the aggregation period is specified in the harvesting step
#' # as data is harvested based on the specified time interval
#' pipe_seq1 <- pipe_seq(p = pdt(
#'    p_step(
#'      dt_n = 1,
#'      dtp_n = 1,
#'      f = "dt_harvest",
#'      f_params = hsf_param_eval()
#'    ),
#' # then aggregate data by month
#'    p_step(
#'      dt_n = 1,
#'      dtp_n = 2,
#'      f = "dt_agg",
#'      f_params = agg_param_eval(
#'        rain_tot = agg_params(phen_out_name = "rain",
#'          agg_f = "mean(x)", units = "mm", measure = "avg"),
#'          agg_offset = c("0 sec", "0 sec"), all_phens = TRUE))
#'        )
#'    )
#' print(pipe_seq1)
#'
#'
#' @author Paul J. Gordijn
#' @export
pipe_seq <- function(
  p = NULL,
  pipe_eval = TRUE,
  ...
) {
  "dtp_n" <- "dt_n" <- "f" <- "time_interval" <-
    "pipe_seq_dt" <- "output_dt" <- NULL
  # make pipe seq table ----
  # generate a pipe_seq table from pipe steps
  # parameters
  if (!any(class(p) %in% "pipe_seq") && !data.table::is.data.table(p)) {
    p <- lapply(p, function(x) {
      x <- data.table::as.data.table(x)
      x$n <- seq_len(nrow(x))
      data.table::setcolorder(x, neworder = c(
        "dt_n", "dtp_n", "n", "f", "f_params", "input_dt",
        "output_dt", "time_interval"
      ))
      return(x)
    })
    p <- data.table::rbindlist(p, fill = TRUE)
    p$start_dttm <- as.POSIXct(NA_character_)
    p$end_dttm <- as.POSIXct(NA_character_)
  }
  p <- split.data.frame(p, f = factor(p$dt_n))

  # evaluate and standardise pipeline options ----
  p <- lapply(seq_along(p), function(i) {
    pii <- p[[i]]
    # harvesting must be first step
    pij <- pii[dt_n == 1 & dtp_n == 1 & !f %in% "dt_harvest"]
    pij <- sapply(seq_along(nrow(pij)[!nrow(pij) %in% 0]), function(ki) {
      message(paste0("The first step (\"dtp_n\" = 1) of each table ",
        "processing stage (\"dt_n\") must begin with harvesting data.",
        collapse = ""
      ))
      message("Use \"dt_harvest()\" function.")
      message(paste0("When \"dt_n\" > 1 the pipeline absorbs data ",
        "from the end of stage one processing (\"dt_n\" == 1).",
        collapse = ""
      ))
      stop("Harvest error", call. = FALSE)
    })

    # check time_intervals
    # only one time_interval per stage
    pij <- pii[!is.na(time_interval)]$time_interval
    pijz <- sapply(
      seq_along(unique(pij))[!seq_along(unique(pij)) %in% 1], function(x) {
        m <- paste0("More than one \'time_interval\' in stage (n) ", i,
          ": ", paste0(unique(pij), collapse = ", "), collapse = ""
        )
        stop(m, call. = FALSE)
      }
    )
    if (length(pij) > 0) pii$time_interval <- pii$time_interval[1]
    rm(pijz)

    # one one output_dt per stage [not including forked tables]
    pij <- pii[!is.na(output_dt)]$output_dt
    pijt <- sapply(
      seq_along(unique(pij))[!seq_along(unique(pij)) %in% 1], function(x) {
        m <- paste0("More than one \'output_dt\' in stage (n) ", i,
          ": ", paste0(unique(pij), collapse = ", "), collapse = ""
        )
        warning(m, call. = FALSE)
        return(pij[1])
      }
    )
    if (length(pij) > 0) pii$output_dt <- pii$output_dt[1]
    rm(pijt)
    invisible(pii)
  })

  # last checks
  for (i in seq_along(p)) {
    # if there is no input data in a stage set this to the last stage output
    if (is.na(p[[i]]$input_dt[1]) && i > 1) {
      p[[i]]$input_dt[1] <- p[[(i - 1)]]$output_dt[1]
    }
    # as for above but with the time interval
    if (is.na(p[[i]]$time_interval[1]) && i > 1) {
      p[[i]]$time_interval <- p[[(i - 1)]]$time_interval[1]
    }
  }
  # check that na values input and output tables & the time interval
  for (i in seq_along(p)) {
    p[[i]][dtp_n > 1 & f != "dt_harvest"]$input_dt <- p[[i]][
      dtp_n == 1
    ]$output_dt[1]
  }
  p <- data.table::rbindlist(p, fill = TRUE)

  if (is.null(p) && is.null(pipe_seq_dt)) p <- NULL
  class(p) <- c(class(p), "pipe_seq")
  return(p)
}