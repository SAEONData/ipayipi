#' @title Pipeline data: processing --- _dt_
#' @description Process data in sequential steps generated by `ipayipi::pipe_seq()`.
#' @param station_file Name of the station being processed.
#' @param pipe_house List of pipeline directories. __See__ `ipayipi::ipip_house()` __for details__.
#' @param pipe_seq Generated processing pipeline structure performed by `ipayipi::pipe_seq()`. Defaults to `NULL`.
#' If this argument is not provided, then the `pipe_seq` stored in the station file will be used for data processing. When changes are made to a stations processing pipeline `overwrite_pipe_memory` should be set to `TRUE`, in which case a `pipe_seq` object must be provided here---this `pipe_seq` will be embedded in the station file.
#' @param overwrite_pipe_memory Logical. If `TRUE` then extant pipeline steps, which are summarised in the 'pipe_process_summary' table (*see details*), are modified by arguments in the pipe_process argument.
#' @param output_dt_preffix The output-table preffix. Defaults is 'dt_'.
#' @param output_dt_suffix A custom suffix to be appended to the output tables name.
#' @param unwanted_tbls Some tables generated by the processing pipeline don't need to be stored permanently in the station file object. By adding keywords to this argument (separated by the '|' character) these 'unwanted' (or temporary) tables will be removed from the station file. Defaults to `_tmp` --- so any table with this search key in its name will be removed.
#' @param verbose Logical. Whether or not to report messages and progress.
#' @param xtra_v Logical. Whether or not to report xtra messages, progess, plus print data tables.
#' @param cores  Number of CPU's to use for processing in parallel. Only applies when working on Linux.
#' @param keep_open Logical. If TRUE the station file connection is kept in the temporary directory after the function is finished processing.
#' @author Paul J. Gordijn
#' @keywords data pipeline; data processing; processing steps
#' @details This function forms the basis of setting up a sequential, data-processing pipeline. In this process, raw or other data from an 'ipayipi' station file is harvested, and further processing of this data can be run.
#'
#'  The first part of the processing stage of the `ipayipi` data pipeline is to set up pipe stages, each with its own sequence of processing steps, using `ipayipi::pipe_seq()`. Once the sequence is set up it can be parsed to `ipayipi::dt_process()`. The four main functions that `ipayipi::dt_process()` uses to process data are:
#'  - `dt_harvest`: for harvesting station/other data.
#'  - `dt_calc_chain`: running `data.table` chained calculations on harvested data.
#'  - `dt_agg`: Aggregate phenomena/variables by custom or default functions.
#'    Defaults are based on the phenomena descriptions in `phens` tables, i.e., their measure, variable type, and units. Default aggregation functions are housed in the `ipayipi::sts_agg_functions` table.
#'  - `dt_join`: Used to merge harvested data sets via simple or comlex 'fuzzy' type joins based on time intervals using `data.table`s join syntax, and ipayipi's own time-series sensitive data joining `ipayipi::append_phen_data()`, implemented through `ipayipi::mhlanga()`.
#'
#'  The above functions can be specified in the `pipe_seq` function. `pipe_seq` runs partial to fuller evaluation of pipeline structure to promote seemless processing. Fuller evaluation by `ipayipi::pipe_seq()` is performed within `ipayipi::dt_process()`; during this process, station data (both internally and externally harvested data) are read so new-phenomena metadata can be generated. All this to minimise potential error during data processing. 
#' Processed data, function parameters, and new phenomena summaries are returned and appended to station files for future use.
#'
#' @export
dt_process <- function(
  station_file = NULL,
  pipe_house = NULL,
  pipe_seq = NULL,
  stages = NULL,
  output_dt_preffix = "dt_",
  output_dt_suffix = NULL,
  overwrite_pipe_memory = FALSE,
  verbose = FALSE,
  unwanted_tbls = "_tmp",
  xtra_v = FALSE,
  keep_open = TRUE,
  ...
) {

  "%ilike%" <- NULL
  "dt_n" <- "dtp_n" <- "ppsid" <- "phen_name" <- "n" <- NULL

  # open station file connection
  sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file,
    verbose = verbose, xtra_v = xtra_v
  )
  if (!is.null(pipe_seq) && any(!"pipe_seq" %in% names(sfc),
        overwrite_pipe_memory
      )) {
    saveRDS(pipe_seq, file.path(dirname(sfc[1]), "pipe_seq"))
  }
  pipe_seq <- sf_dta_read(
    sfc = sfc, tv = "pipe_seq", verbose = FALSE
  )[["pipe_seq"]]

  # clean up any temp data
  mfiles <- c("hsf_dts", "dt_working")
  unlink(sfc[mfiles[mfiles %in% names(sfc)]], recursive = TRUE)

  # purge station dt misc files
  mfiles <- names(sfc)[names(sfc) %ilike% "dt_working|_hsf_table_"]
  if (overwrite_pipe_memory) {
    mfiles <- c(mfiles, "phens_dt", "f_params", names(sfc)[
      names(sfc) %ilike% "^dt_"
    ])
  }
  unlink(sfc[mfiles[mfiles %in% names(sfc)]], recursive = TRUE)
  sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file)

  # read function summary tables
  # open output_dt and associate table summary
  sf_names <- names(sfc)
  f_summary <- sf_dta_read(pipe_house = pipe_house, sfc = sfc,
    tv = sf_names[sf_names %ilike% "summary|phens|pipe_seq"],
    verbose = FALSE
  )
  f_summary$sf_names <- sf_names

  ## standardise the overall pipe process summary
  pps <- f_summary$pipe_seq
  pp <- pipe_process(pipe_seq = pipe_seq, pipe_memory = pps,
    overwrite_pipe_memory = overwrite_pipe_memory
  )

  if (pp$update_pipe_data || !"f_params" %in% names(sfc)) {
    # prep pps for partial evaluation
    pps <- pp$pipe_seq
    pps <- split(pps, f = factor(pps$dt_n))
    saveRDS(pp$pipe_seq, file.path(dirname(sfc[1]), "pipe_seq"))
  } else {# no eval if NULL --- sf already has pps and f_params
    pps <- NULL
  }

  # pps full evaluation ----
  # set up paired functions
  ff <- list(
    list("dt_harvest", "dt_calc", "dt_agg", "dt_join"),
    list("hsf_param_eval", "calc_param_eval", "agg_param_eval",
      "join_param_eval"
    ),
    list("hsf_params", "calc_params", "agg_params", "join_params")
  )

  # pipeline evaluation -------------------------------------------------------
  # full evaluation of the pipeline then save evaluated f_params to function
  #  tables seq_along(pps)
  lapply(seq_along(pps), function(i) {
    ppsi <- pps[[i]]
    lapply(unique(ppsi$dtp_n), function(j) {
      sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file)
      # get function and prepare arguments
      ppsij <- ppsi[dtp_n == j]
      f <- ppsij$f[1]
      f <- ff[[2]][ff[[1]] %in% f][[1]]
      if (!f %in% c("calc_param_eval", "agg_param_eval")) {
        t <- ppsij$f_params[1]
        t <- gsub("\\.\\(", "list\\(", t)
        f_params <- eval(parse(text = t))
        class(f_params) <- unique(c("f_params", class(f_params)))
      } else {
        f_params <- NULL
      }
      cr_msg <- padr(core_message = paste0(i, "-", j, ": ", f, collapes = ""),
        wdth = 80, pad_char = " ", pad_extras = c("|", "", "", "|"),
        force_extras = FALSE, justf = c(-1, 3)
      )
      ipayipi::msg(cr_msg, verbose)
      args <- list(station_file = station_file, f_params = f_params,
        ppsij = ppsij, full_eval = TRUE, sfc = sfc, verbose = verbose,
        xtra_v = xtra_v
      )
      o <- do.call(what = f, args = args)

      fo <- o$f_params
      sfc_f_params <- sf_dta_read(sfc = sfc, tv = "f_params")
      sfc_f_params_n <- names(sfc_f_params$f_params)
      if (length(sfc_f_params) == 0) sfc_f_params <- NULL
      sfc_f_params <- unlist(sfc_f_params, recursive = FALSE)
      names(sfc_f_params) <- sfc_f_params_n
      o <- o[!names(o) %in% "f_params"]
      oo <- sf_dta_read(sfc = sfc, tv = names(o),
        pipe_house = pipe_house, station_file = station_file, tmp = TRUE,
        verbose = FALSE
      )
      if (length(oo) == 0) oo <- NULL
      o <- append_tables(original_tbl = oo, new_tbl = o)
      fo <- append_tables(original_tbl = sfc_f_params, new_tbl = fo)

      # clean up phens dt
      if (!is.null(o$phens_dt)) {
        o$phens_dt <- o$phens_dt[
          order(as.numeric(gsub("_", ".", o$phens_dt$ppsid), phen_name))
        ]
        # fill NA with option duplicates
        o$phens_dt$i <- substr(o$phens_dt$ppsid, 1,
          unlist(gregexpr("_", o$phens_dt$ppsid)) - 1
        )
        opdt <- split.data.frame(o$phens_dt, f = paste(
          o$phens_dt$i, o$phens_dt$orig_table_name, o$phens_dt$table_name,
          o$phens_dt$phen_name
        ))
        opdt <- lapply(opdt, function(x) {
          fna <- function(x, y) {
            if (any(!is.na(x[[y]]))) {
              x[is.na(x[[y]]), y]  <- x[[y]][!is.na(x[[y]])][1]
            }
            return(x)
          }
          x <- fna(x, "phid")
          x <- fna(x, "units")
          x <- fna(x, "measure")
          x <- fna(x, "var_type")
          x <- unique(x)
          x <- x[, names(x)[!names(x) %in% c("i", "j")], with = FALSE]
        })
        o$phens_dt <- data.table::rbindlist(opdt)
        o$phens_dt[
          as.numeric(order(gsub("_", ".", o$phens_dt$ppsid), phen_name))
        ]
      }
      # save f params
      fo <- fo[!sapply(fo, is.null)]
      if (!is.null(fo$agg_params)) fo$agg_params <- unique(fo$agg_params)
      class(fo) <- c(class(fo), "f_params")
      o <- list(f_params = fo, phens_dt = o$phens_dt)
      lapply(names(o), function(x) {
        saveRDS(o[[x]], file.path(dirname(sfc[1]), x))
      })
      return(o)
    })
  })
  sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file)
  pps <- sf_dta_read(sfc = sfc, tv = "pipe_seq", verbose = FALSE
  )[["pipe_seq"]]
  if (!is.null(stages)) {
    pps <- pps[dt_n >= min(stages)][dt_n <= max(stages)]
  }
  pps <- split(pps, f = factor(pps$dt_n))

  # processing_along(pps) data ------------------------------------------------
  piit <- lapply(seq_along(pps), function(i) {
    ppsi <- pps[[i]]
    pit <- lapply(unique(ppsi$dtp_n), function(j) {
      sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file)
      # get function and prepare arguments
      ppsij <- ppsi[dtp_n == j]
      f <- ppsij$f[1]
      fpm <- sf_dta_read(sfc = sfc, tv = "f_params")
      if (!f %in% c("dt_calc", "dt_join")) {
        f_params <- fpm[["f_params"]][[ff[[3]][ff[[1]] %in% f][[1]]]][
          ppsid == paste0(ppsi$dt_n[1], "_", j)
        ]
      } else {
        f_params <- as.list(ppsij$f_params)
      }
      cr_msg <- padr(
        core_message = paste0(ppsi$dt_n[1], "-", j, ": ", f, collapes = ""),
        wdth = 80, pad_char = " ", pad_extras = c("|", "", "", "|"),
        force_extras = FALSE, justf = c(-1, 3)
      )
      ipayipi::msg(cr_msg, verbose)
      # get arguments and process function
      args <- list(station_file = station_file, f_params = f_params,
        ppsij = ppsij, sfc = sfc, verbose = verbose, xtra_v = xtra_v
      )
      ppsij_ud <- do.call(what = f, args = args)
      # gp <- sf_dta_read(sfc, tv = "gaps")[["gaps"]][
      #   table_name %in% ppsij$output_dt
      # ]
      # message("Gap table")
      # print(gp)
      return(ppsij_ud$ppsij)
    })
    pit <- data.table::rbindlist(pit)
    sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file)

    # convert dt_working to output_dt
    odtn <- unique(ppsi$output_dt)[1]

    # will need some append step here --- can't just rename
    if (overwrite_pipe_memory && "dt_working" %in% names(sfc)) {
      unlink(file.path(sfc[1], odtn), recursive = TRUE)
    }
    # append to chunked file or create new one
    dw <- sf_dta_read(sfc = sfc, tv = "dt_working")
    lapply(dw$dt_working$fs, function(w) {
      sf_dta_chunkr(dta_room = file.path(dirname(sfc)[1], odtn),
        dta_sets = list(readRDS(w)), tn = odtn, verbose = verbose,
        xtra_v = xtra_v, ri = dw$dt_working$indx$ri, rit =
          dw$dt_working$indx$rit
      )
    })
    # write a normal file if not chunked
    if (is.null(dw$dt_working$fs) && length(dw) > 0) {
      dta <- dt_dta_open(dw)
      sf_dta_wr(dta_room = file.path(dirname(sfc)[1], odtn),
        tn = odtn, dta = dta, verbose = verbose, xtra_v = xtra_v
      )
    }
    unlink(sfc["dt_working"], recursive = TRUE)
    return(pit)
  })
  piit <- data.table::rbindlist(piit)
  opiit <- readRDS(file.path(dirname(sfc[1]), "pipe_seq"))
  piit <- rbind(opiit[!dt_n %in% piit$dt_n], piit)
  piit <- piit[order(dt_n, dtp_n, n)]
  saveRDS(piit, file.path(dirname(sfc[1]), "pipe_seq"))
  sfc <- open_sf_con(
    pipe_house = pipe_house, station_file = station_file
  )
  unwanted_tbls <- paste0(c(unwanted_tbls, "_hsf_table_"), collapse = "|")
  unwanted_tbls <- names(sfc)[names(sfc) %ilike% unwanted_tbls]
  if (length(unwanted_tbls) == 0) unwanted_tbls <- NULL
  sapply(unwanted_tbls, function(x) unlink(sfc[x], recursive = TRUE))
  write_station(pipe_house = pipe_house, station_file = station_file,
    overwrite = TRUE
  )
  return(station_file)
}