#' @title Pipeline data processing: _dt_
#' @description Process data in sequential steps generated by `ipayipi::pipe_seq()`.
#' @param station_file Name of the station being processed.
#' @param pipe_house List of pipeline directories. __See__ `ipayipi::ipip_init()` __for details__.
#' @param pipe_seq Generated processing pipeline structure performed by `ipayipi::pipe_seq()`.
#' @param output_dt_preffix The output table preffix which defaults to "dt_".
#' @param output_dt_suffix A custom suffix to be appended to the output tables name.
#' @param overwrite_pipe_memory Logical. If TRUE then extant pipeline steps, which are summarised in the 'pipe_process_summary' data table (*see
#'  details*), are modified by arguments in the pipe_process argument.
#' @author Paul J. Gordijn
#' @keywords data pipeline; data processing; processing steps
#' @details This function forms the basis of setting up a sequential data processing pipeline. This allows the extraction and preparation of raw, or other data from a data table in an 'ipayipi' station file, and further processing of this data.
#'
#'  The first part of the processing stage of the `ipayipi` data pipeline is to set up a pipe stage and step sequence using `ipayipi::pipe_seq()`. Once the sequence is set up it can be parsed to `ipayipi::dt_process()`. The four main functions that `ipayipi::dt_process()` uses to process data are:
#'  - `dt_harvest`: for harvesting station/other data.
#'  - `dt_calc_chain`: running `data.table` chained calculations on data.
#'  - `dt_agg`: Aggregate phenomena/variables by custom or default functions.
#'    Defaults are based on the phenomena descriptions in `phens` tables, i.e., their measure, variable type, and units.
#'  - `dt_join`: Used to merge harvested data sets together via simple and more comlex fuzzy type joins using `data.table`.
#'  These functions can be specified in the `pipe_seq` function. `pipe_seq` will itself run some basic checks on the pipeline structure and to help ensure smooth running of the processing. More complex checks on the structure of the pipeline are done in the `dt_process` function using full evaluation of the functions mentioned above. During this process station data (both external for external harvesting) and the station wherein data are being processed are opened and new phenomena descriptions are  generated. Function parameters are also generated for each of the functions above. All this to minimise potential error during the actual data processing performed by the functions above. 
#' Processed data, function parameters, and new phenomena summariies are returned and appended to station files for future use.
#'
#' @export
dt_process <- function(
  station_file = NULL,
  pipe_house = NULL,
  pipe_seq = NULL,
  output_dt_preffix = "dt_",
  output_dt_suffix = NULL,
  overwrite_pipe_memory = FALSE,
  verbose = FALSE,
  unwanted_tbls = "_tmp",
  ...
) {
  "%ilike%" <- "dt_n" <- "dtp_n" <- "ppsid" <- "phen_name" <- "ii" <-
    "jj" <- ".N" <- "agg_options" <- NULL

  # open station file connection
  sfc <- ipayipi::open_sf_con(pipe_house = pipe_house, station_file =
    station_file, tmp = FALSE)
  if (!is.null(pipe_seq) && any(!"pipe_seq" %in% names(sfc),
    overwrite_pipe_memory)) {
    saveRDS(pipe_seq, file.path(dirname(sfc[1]), "pipe_seq"))
  }
  if (is.null(pipe_seq)) {
    pipe_seq <- ipayipi::sf_read(
      sfc = sfc, tmp = TRUE, tv = "pipe_seq", verbose = FALSE)[["pipe_seq"]]
  }
  # clean up any temp data
  mfiles <- c("hsf_dts", "dt_working")
  unlink(sfc[mfiles[mfiles %in% names(sfc)]], recursive = TRUE)

  # purge station dt misc files
  if (overwrite_pipe_memory) {
    mfiles <- c("phens_dt", "f_params", names(sfc)[
      names(sfc) %ilike% "^dt_|_hsf_table_"])
    unlink(sfc[mfiles[mfiles %in% names(sfc)]], recursive = TRUE)
    sfc <- ipayipi::open_sf_con(pipe_house = pipe_house, station_file =
      station_file, tmp = TRUE)
  }

  # read function summary tables
  # open output_dt and associate table summary
  sf_names <- names(sfc)
  f_summary <- ipayipi::sf_read(pipe_house = pipe_house, sfc = sfc, tmp = TRUE,
    tv = sf_names[sf_names %ilike% "summary|phens|pipe_seq"],
    station_file = station_file, verbose = FALSE)
  f_summary$sf_names <- sf_names
  #dt_names <- sf_names[sf_names %ilike% output_dt_preffix]

  # get dttm max min dates
  # sf_slice <- lapply(seq_along(dt_names), function(i) {
  #   dt_working <- ipayipi::sf_read(sfc = sfc, tmp = TRUE, tv = dt_names[i])[[
  #     dt_names[i]
  #   ]]
  #   return(list(
  #     sf_min = min(dt_working$date_time),
  #     sf_max = max(dt_working$date_time))
  #   )
  # })
  # names(sf_slice) <- dt_names

  ## standardise the overall pipe process summary
  pps <- f_summary$pipe_seq
  pp <- pipe_process(pipe_seq = pipe_seq, pipe_memory = pps,
    overwrite_pipe_memory = overwrite_pipe_memory)

  if (pp$update_pipe_data) {
    # prep pps for partial evaluation
    pps <- pp$pipe_seq
    pps <- split(pps, f = factor(pps$dt_n))
    saveRDS(pp$pipe_seq, file.path(dirname(sfc[1]), "pipe_seq"))
  } else {# no eval if NULL --- sf already has pps
    pps <- NULL
    # message("No \'pipe_seq\' detected!")
  }

  # pps full evaluation ----
  # set up paired functions
  ff <- list(
    list("dt_harvest", "dt_calc", "dt_agg", "dt_join"),
    list("hsf_param_eval", "calc_param_eval", "agg_param_eval",
      "join_param_eval"),
    list("hsf_params", "calc_params", "agg_params", "join_params")
  )

  # pipeline evaluation -------------------------------------------------------
  # full evaluation of the pipeline then save evaluated f_params to function
  #  tables
  ii <- lapply(seq_along(pps), function(i) {
    ppsi <- pps[[i]]
    jj <- lapply(seq_along(unique(ppsi$dtp_n)), function(j) {
      sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file,
        tmp = TRUE)
      # get function and prepare arguments
      ppsij <- ppsi[dt_n == i & dtp_n == j, ]
      f <- ppsij$f[1]
      f <- ff[[2]][ff[[1]] %in% f][[1]]
      if (!f %in% c("calc_param_eval", "agg_param_eval")) {
        f_params <- eval(parse(text = ppsij$f_params[1]))
        class(f_params) <- c("f_params", "list")
      } else {
        f_params <- NULL
      }
      cr_msg <- padr(core_message =
          paste0(f, ": ", i, "-", j, collapes = ""),
        wdth = 80, pad_char = " ", pad_extras = c("|", "", "", "|"),
        force_extras = FALSE, justf = c(1, 3))
      ipayipi::msg(cr_msg, verbose)
      args <- list(
        station_file = station_file,
        f_params = f_params,
        ppsij = ppsij,
        full_eval = TRUE,
        sfc = sfc
      )
      o <- do.call(what = f, args = args)

      fo <- o$f_params
      sfc_f_params <- ipayipi::sf_read(sfc = sfc, tv = "f_params",
        pipe_house = pipe_house, station_file = station_file, tmp = TRUE,
        verbose = FALSE)
      sfc_f_params_n <- names(sfc_f_params$f_params)
      if (length(sfc_f_params) == 0) sfc_f_params <- NULL
      sfc_f_params <- unlist(sfc_f_params, recursive = FALSE)
      names(sfc_f_params) <- sfc_f_params_n
      o <- o[!names(o) %in% "f_params"]
      oo <- ipayipi::sf_read(sfc = sfc, tv = names(o),
        pipe_house = pipe_house, station_file = station_file, tmp = TRUE,
        verbose = FALSE)
      if (length(oo) == 0) oo <- NULL
      o <- ipayipi::append_tables(original_tbl = oo, new_tbl = o)
      fo <- ipayipi::append_tables(original_tbl = sfc_f_params, new_tbl = fo)

      # clen up phens dt
      if (!is.null(o$phens_dt)) {
        o$phens_dt <- o$phens_dt[order(ppsid, phen_name)]
        o$phens_dt$i <- substr(o$phens_dt$ppsid, 1,
          unlist(gregexpr("_", o$phens_dt$ppsid)) - 1)
        opdt <- split.data.frame(o$phens_dt, f = paste(
          o$phens_dt$i, o$phens_dt$orig_table_name, o$phens_dt$table_name,
          o$phens_dt$phen_name))
        opdt <- lapply(opdt, function(x) {
          fna <- function(x, y) {
            if (any(!is.na(x[[y]]))) {
              x[is.na(x[[y]]), y]  <- x[[y]][!is.na(x[[y]])][1]
            }
            return(x)
          }
          x <- fna(x, "units")
          x <- fna(x, "measure")
          x <- fna(x, "var_type")
          x <- unique(x)
          x <- x[, names(x)[!names(x) %in% c("i", "j")], with = FALSE]
        })
        o$phens_dt <- data.table::rbindlist(opdt)
      }
      fo <- fo[!sapply(fo, is.null)]
      if (!is.null(fo$agg_params)) fo$agg_params <- unique(fo$agg_params)
      o <- list(f_params = fo, phens_dt = o$phens_dt)
      lapply(names(o), function(x) {
        saveRDS(o[[x]], file.path(dirname(sfc[1]), x))
      })
      return(o)
    })
    rm(jj)
  })
  sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file,
      tmp = TRUE)
  pps <- ipayipi::sf_read(pipe_house = pipe_house, sfc = sfc, tmp = TRUE,
    tv = "pipe_seq", verbose = FALSE)[["pipe_seq"]]
  pps <- split(pps, f = factor(pps$dt_n))

  # process data --------------------------------------------------------------
  lapply(seq_along(pps), function(i) {
    ppsi <- pps[[i]]
    sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file,
      tmp = TRUE)
    if ("dt_working" %in% names(sfc)) {
      unlink(sfc["dt_working"], recursive = TRUE)
    }
    lapply(seq_along(unique(ppsi$dtp_n)), function(j) {
      sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file,
        tmp = TRUE)
      # get function and prepare arguments
      ppsij <- ppsi[dt_n == i & dtp_n == j, ]
      f <- ppsij$f[1]
      fpm <- ipayipi::sf_read(sfc = sfc, tv = "f_params", tmp = TRUE,
        station_file = station_file, verbose = FALSE)
      if (!f %in% c("dt_calc", "dt_join")) {
        f_params <- fpm[["f_params"]][[ff[[3]][ff[[1]] %in% f][[1]]]][
          ppsid == paste0(i, "_", j)]
      } else {
        f_params <- as.list(ppsij$f_params)
      }
      cr_msg <- padr(core_message =
          paste0(f, ": ", i, "-", j, collapes = ""),
        wdth = 80, pad_char = " ", pad_extras = c("|", "", "", "|"),
        force_extras = FALSE, justf = c(1, 3))
      ipayipi::msg(cr_msg, verbose)
      # get arguments and process function
      args <- list(
        station_file = station_file,
        f_params = f_params,
        ppsij = ppsij,
        sfc = sfc
      )
      dti <- do.call(what = f, args = args)
      # if there is hsf data and no dt working create dt working table
      # if (any(names(dti) %in% "hsf_dts") &&
      #   !any(names(sfc) %in% "dt_working")) {
      #     dl <- length(dti$hsf_dts)
      #     sapply(seq_len(dl - 1), function(xi) {
      #       warning("More than one harvested dataset. Using latest harvest.")
      #     })
      #     dti$dt_working <- dti$hsf_dts[[length(dti$hsf_dts)]]
      # }
      # lapply(names(dti), function(x) {
      #   saveRDS(dti[[x]], file.path(dirname(sfc[1]), x))
      # })
    })
    sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file,
      tmp = TRUE)
    # convert dt_working to output_dt
    odtn <- unique(ppsi$output_dt)
    file.rename(sfc["dt_working"], file.path(dirname(sfc["dt_working"]), odtn))
  })
  sfc <- open_sf_con(pipe_house = pipe_house, station_file = station_file,
    tmp = TRUE)
  unwanted_tbls <- paste0(c(unwanted_tbls, "_hsf_table_"), collapse = "|")
  unwanted_tbls <- names(sfc)[names(sfc) %ilike% unwanted_tbls]
  if (length(unwanted_tbls) == 0) unwanted_tbls <- NULL
  sapply(unwanted_tbls, function(x) {
    unlink(sfc[x], recursive = TRUE)
  })
  ipayipi::write_station(pipe_house = pipe_house, station_file = station_file,
    overwrite = TRUE)
  return(station_file)
}