#' @title Batch processing of pipeline data: _dt_
#' @description Batch process ipayipi station data data by stages and steps. First processing steps are evaluated to build relevant metadata, then data is accordingly processed.
#' @inheritParams logger_data_import_batch
#' @inheritParams dta_list
#' @inheritParams imbibe_raw_batch
#' @param pipe_seq A `pipe_seq` object descirbes sequential data processing stages and steps in iPayipi. A `pipe_seq` can be build using `ipayipi::pipe_seq()`. Defaults to `NULL`.
#' * If this argument is provided, then upon its successful evaluation, the `pipe_seq` is embedded a respective station file with associated metadata.
#' * If this argument is not provided then the embedded `pipe_seq` (if there is one) will be used for data processing. To overwrite an existing stations `pipe_seq` set `overwrite_pipe_memory` to `TRUE`, and provide the new `pipe_seq` object to this argument.
#' @param overwrite_pipe_memory Logical. If `TRUE` then the stations pipeline steps, that are described by the `pipe_seq` object/table, are overwritten by the new `pipe_seq` object.
#' @param stages Integer vector denoting the consecutive stages of the `pipe_seq` object to process. Can be used to split a processing pipeline to allow additional processing between stages in the interlude (note: each stage contains multiple steps).  Set to `0` (zero) for only running `pipe_seq` evaluation.
#' @param output_dt_preffix The output table preffix which defaults to "dt_".
#' @param output_dt_suffix A custom suffix to be appended to the output tables name.
#' @param station_ext The extension of the station file. Defaults to 'ipip'.
#' @param unwanted_tbls Some tables generated by the processing pipeline don't need to be stored permanently in the station file object. By adding keywords to this argument (separated by the '|' character) these 'unwanted' (or temporary) tables will be removed from the station file. Defaults to `_tmp` --- so any table with this search key in its name will be removed.
#' @author Paul J. Gordijn
#' @keywords data processing; time series data; data calculations; data transformations; data aggregation; join data; join event metadata
#' @details This function forms the basis of setting up a sequential, data-processing pipeline. In this process, raw or other data from an 'ipayipi' station file is harvested, and further processing of this data can be run.
#'
#'  The first part of the processing stage of the `ipayipi` data pipeline is to set up pipe stages, each with its own sequence of processing steps, using [pipe_seq()]. Once the sequence is set up it can be parsed to [dt_process()]. The six main functions that [dt_process_batch()] uses to process data are:
#'  - [dt_harvest()]: for harvesting station/other data.
#'  - [dt_calc()]: running `data.table` chained calculations on harvested data.
#'  - [dt_agg()]: Aggregate phenomena/variables by custom or default functions.
#'    Defaults functions are determined by phenomena descriptions in `phens` tables, i.e., their measure, variable type, and units. Default aggregation functions are housed in the [ipayipi::sts_agg_functions] table.
#'  - [dt_join()]: Used to merge harvested data sets via simple or comlex 'fuzzy' type joins based on time intervals using `data.table`s join syntax, and ipayipi's own time-series sensitive data joining [append_phen_data()], implemented through [mhlanga()].
#'  - [dt_clean()]: A recursive, temporally segmented filter used to detect anomalies and impute data through applicaiton of a generalised Hampel signal processing. _This is a new function and under current development._
#'  - [dt_drift()]: Used to correct time series data based on calibraion readings.  _This is a new function and under current development._
#'
#'  The above functions can be specified in the `pipe_seq` function. `pipe_seq` runs partial to fuller evaluation of pipeline structure to promote seemless processing. Fuller evaluation of a [pipe_seq()] is performed within [dt_process_batch()]; during this process, station data (both internally and externally harvested data) are read so new-phenomena metadata can be generated. All this to minimise potential error during data processing.
#' Processed data, function parameters, and new phenomena summaries are returned and appended to station files for future use.
#'
#' ## Raw station data: It is not recommended to edit raw station data. The recommended/default preffix for raw station data table<s in iPayipi begins with the preffix \strong{raw_}, followed by the standard record interval strong, e.g., 'raw_5_mins'.
#'
#' ##`stages`: When splitting up stages, if proceeeding stages rely on the outputs of preceeding steps, there will be problems in processing down the pipeline. Note that any `output_dt` ending in '_tmp' is not saved to a station file. Therefore, if a processing pipeline has to be interupted using `stages`, e.g. for data imputation, then avoid saving outputs with the '_tmp' suffix.
#'
#' ## `pipe_seq` and pipeline evaluation
#' Pipeline evaluation is done parially when first describing the various pipeline stages and steps. Evaluation is done using a separate function for each step operation.
#'
#' ## Reserved characters
#' * 'dt_': This is the recommended suffix for tables produced using `dt_process_batch()` or `dt_process`.
#' * '_tmp': used as a suffix on temporary output tables. These are removed from station files at the end of processing steps (or after completing set `stages`).
#' * '_fltr_': substring in the table name used to store original and replacement values as produced by [dt_clean()].
#' @export
dt_process_batch <- function(
  pipe_house = NULL,
  pipe_seq = NULL,
  stages = NULL,
  overwrite_pipe_memory = FALSE,
  output_dt_preffix = "dt_",
  output_dt_suffix = NULL,
  wanted = NULL,
  unwanted = NULL,
  prompt = FALSE,
  unwanted_tbls = "_tmp",
  verbose = FALSE,
  xtra_v = FALSE,
  chunk_v = FALSE,
  dt_format = c(
    "Ymd HMOS", "Ymd HMS",
    "Ymd IMOSp", "Ymd IMSp",
    "ymd HMOS", "ymd HMS",
    "ymd IMOSp", "ymd IMSp",
    "mdY HMOS", "mdY HMS",
    "mdy HMOS", "mdy HMS",
    "mdy IMOSp", "mdy IMSp",
    "dmY HMOS", "dmY HMS",
    "dmy HMOS", "dmy HMS",
    "dmy IMOSp", "dmy IMSp"
  ),
  dt_tz = "Africa/Johannesburg",
  future.stdout = TRUE,
  ...
) {

  station_ext <- ".ipip"

  # get list of station names in the ipip directory
  station_files <- ipayipi::dta_list(
    input_dir = pipe_house$ipip_room, file_ext = station_ext, prompt = prompt,
    recurr = FALSE, baros = FALSE, unwanted = unwanted, wanted = wanted
  )

  if (verbose || xtra_v || chunk_v) {
    cli::cli_h1("Data processing: {length(station_files)} station file{?s}")
  }
  if (fcoff()) {
    xtra_v <- FALSE
    chunk_v <- FALSE
  }
  # update and/or create new stations
  # upgraded_stations <- lapply(seq_along(new_station_files), function(i) {

  future.apply::future_lapply(seq_along(station_files), function(i) {
    dtp <- attempt::attempt(dt_process(station_file = station_files[i],
      pipe_house = pipe_house, pipe_seq = pipe_seq, stages = stages,
      output_dt_preffix = output_dt_preffix,
      output_dt_suffix = output_dt_suffix,
      overwrite_pipe_memory = overwrite_pipe_memory,
      verbose = verbose, xtra_v = xtra_v, chunk_v = chunk_v
    ))
    return(station_files[i])
  }, future.seed = TRUE, future.stdout = future.stdout)

  if (verbose || xtra_v || chunk_v) {
    cli::cli_h1("")
  }
  invisible()
}