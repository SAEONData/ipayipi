#' @title Pipeline data: processing --- _dt_
#' @description Process data in sequential steps generated by `ipayipi::pipe_seq()`.
#' @param station_file Name of the station being processed.
#' @inheritParams dt_process_batch
#' @author Paul J. Gordijn
#' @keywords data pipeline; data processing; processing steps
#' @details This function is called by [dt_process_batch()] and its documentation described therein.
#' @export
dt_process <- function(
  station_file = NULL,
  pipe_house = NULL,
  pipe_seq = NULL,
  stages = NULL,
  output_dt_preffix = "dt_",
  output_dt_suffix = NULL,
  overwrite_pipe_memory = FALSE,
  unwanted_tbls = "_tmp",
  verbose = FALSE,
  xtra_v = FALSE,
  chunk_v = FALSE,
  dt_format = c(
    "Ymd HMOS", "Ymd HMS",
    "Ymd IMOSp", "Ymd IMSp",
    "ymd HMOS", "ymd HMS",
    "ymd IMOSp", "ymd IMSp",
    "mdY HMOS", "mdY HMS",
    "mdy HMOS", "mdy HMS",
    "mdy IMOSp", "mdy IMSp",
    "dmY HMOS", "dmY HMS",
    "dmy HMOS", "dmy HMS",
    "dmy IMOSp", "dmy IMSp"
  ),
  dt_tz = "Africa/Johannesburg",
  ...
) {

  "%ilike%" <- "%chin%" <- NULL
  "dt_n" <- "dtp_n" <- "ppsid" <- "phen_name" <- "n" <- NULL

  if (verbose || xtra_v || chunk_v) {
    cli::cli_h2(c("Processing {station_file} ..."))
  }
  # open station file connection
  sfc <- sf_open_con(pipe_house = pipe_house, station_file = station_file,
    chunk_v = chunk_v
  )
  # delete old pipe_seq if necessary -- and replace with new
  if (!is.null(pipe_seq) &&
      any(!"pipe_seq" %chin% names(sfc), overwrite_pipe_memory)
  ) {
    sf_dta_rm(sfc = sfc, rm = "pipe_seq")
    sl <- sf_dta_wr(dta_room = file.path(dirname(sfc[1]), "pipe_seq"),
      dta = pipe_seq, tn = "pipe_seq"
    )
    sf_log_update(sfc = sfc, log_update = sl)
  }
  pipe_seq <- sf_dta_read(sfc = sfc, tv = "pipe_seq")[["pipe_seq"]]

  # clean up any temp data
  mfiles <- c("hsf_dts", "dt_working")
  sf_dta_rm(sfc = sfc, rm = mfiles)

  # purge station dt misc files
  mfiles <- names(sfc)[names(sfc) %ilike% "dt_working|_hsf_table_"]
  if (overwrite_pipe_memory) {
    mfiles <- c(
      mfiles, "phens_dt", "f_params", names(sfc)[names(sfc) %ilike% "^dt_"]
    )
  }
  sf_dta_rm(sfc = sfc, rm = mfiles)
  sfc <- sf_open_con(sfc = sfc)

  # read function summary tables
  # open output_dt and associate table summary
  sf_names <- names(sfc)
  f_summary <- sf_dta_read(sfc = sfc,
    tv = sf_names[sf_names %ilike% "summary|phens|pipe_seq"],
  )
  f_summary$sf_names <- sf_names

  ## standardise the overall pipe process summary
  pps <- f_summary$pipe_seq
  pp <- pipe_process(pipe_seq = pipe_seq, pipe_memory = pps,
    overwrite_pipe_memory = overwrite_pipe_memory
  )

  if (pp$update_pipe_data || !"f_params" %in% names(sfc)) {
    # prep pps for partial evaluation
    pps <- pp$pipe_seq
    pps <- split(pps, f = factor(pps$dt_n))
    sl <- sf_dta_wr(dta_room = file.path(dirname(sfc[1]), "pipe_seq"),
      dta = pp$pipe_seq, tn = "pipe_seq"
    )
    sf_log_update(sfc = sfc, log_update = sl)
  } else {# no eval if NULL --- sf already has pps and f_params
    pps <- NULL
  }

  # pps full evaluation ----
  # set up paired functions
  ff <- list(
    list("dt_harvest", "dt_calc", "dt_agg", "dt_join", "dt_clean", "dt_drift"),
    list("hsf_param_eval", "calc_param_eval", "agg_param_eval",
      "join_param_eval", "clean_param_eval", "drift_param_eval"
    ),
    list("hsf_params", "calc_params", "agg_params", "join_params",
      "clean_params", "drift_params"
    )
  )

  # pipeline evaluation -------------------------------------------------------
  # full evaluation of the pipeline then save evaluated f_params to function
  #  tables seq_along(pps)
  lapply(seq_along(pps), function(i) {
    ppsi <- pps[[i]]
    lapply(unique(ppsi$dtp_n), function(j) {
      sfc <- sf_open_con(sfc = sfc)
      # get function and prepare arguments
      ppsij <- ppsi[dtp_n == j]
      f <- ppsij$f[1]
      f <- ff[[2]][ff[[1]] %in% f][[1]]
      if (!f %in% c("calc_param_eval", "agg_param_eval", "clean_param_eval",
          "drift_param_eval"
        )
      ) {
        t <- ppsij$f_params[1]
        t <- gsub("\\.\\(", "list\\(", t)
        f_params <- eval(parse(text = t))
        class(f_params) <- unique(c("f_params", class(f_params)))
      } else {
        f_params <- NULL
      }
      if (verbose || xtra_v || chunk_v) {
        cli::cli_h3(c("evaluating {station_file}: {i}-{j}: {f}"))
      }
      args <- list(station_file = station_file,
        f_params = f_params, ppsij = ppsij, full_eval = TRUE, sfc = sfc,
        verbose = verbose, xtra_v = xtra_v, chunk_v = chunk_v
      )
      o <- do.call(what = f, args = args)

      fo <- o$f_params
      sfc_f_params <- sf_dta_read(sfc = sfc, tv = "f_params")
      sfc_f_params_n <- names(sfc_f_params$f_params)
      if (length(sfc_f_params) == 0) sfc_f_params <- NULL
      sfc_f_params <- unlist(sfc_f_params, recursive = FALSE)
      names(sfc_f_params) <- sfc_f_params_n
      o <- o[!names(o) %in% "f_params"]
      oo <- sf_dta_read(sfc = sfc, tv = names(o))
      if (length(oo) == 0) oo <- NULL
      o <- append_tables(original_tbl = oo, new_tbl = o)
      fo <- append_tables(original_tbl = sfc_f_params, new_tbl = fo)

      # clean up phens dt
      if (!is.null(o$phens_dt)) {
        o$phens_dt <- o$phens_dt[
          order(as.numeric(gsub("_", ".", o$phens_dt$ppsid), phen_name))
        ]
        # fill NA with option duplicates
        o$phens_dt$i <- substr(o$phens_dt$ppsid, 1,
          unlist(gregexpr("_", o$phens_dt$ppsid)) - 1
        )
        opdt <- split.data.frame(o$phens_dt, f = paste(
          o$phens_dt$i, o$phens_dt$orig_table_name, o$phens_dt$table_name,
          o$phens_dt$phen_name
        ))
        opdt <- lapply(opdt, function(x) {
          x <- fna(x, "phid")
          x <- fna(x, "units")
          x <- fna(x, "measure")
          x <- fna(x, "var_type")
          x <- unique(x)
          x <- x[, names(x)[!names(x) %in% c("i", "j")], with = FALSE]
        })
        o$phens_dt <- data.table::rbindlist(opdt)
        o$phens_dt[
          as.numeric(order(gsub("_", ".", o$phens_dt$ppsid), phen_name))
        ]
        # stop eval if there is no described record interval
        if (any(is.na(o$phens_dt$dt_record_interval))) {
          stop("NA record interval")
        }
      }
      # save f params
      fo <- fo[!sapply(fo, is.null)]
      if (!is.null(fo$agg_params)) fo$agg_params <- unique(fo$agg_params)
      class(fo) <- c(class(fo), "f_params")
      o <- list(f_params = fo, phens_dt = o$phens_dt)
      o <- o[!sapply(o, is.null)]
      lapply(names(o), function(x) {
        sl <- sf_dta_wr(dta_room = file.path(dirname(sfc[1]), x),
          dta = o[[x]], tn = x
        )
        sf_log_update(sfc = sfc, log_update = sl)
      })
      return(o)
    })
  })
  sfc <- sf_open_con(sfc = sfc)
  pps <- sf_dta_read(sfc = sfc, tv = "pipe_seq")[["pipe_seq"]]
  if (!is.null(stages)) {
    pps <- pps[dt_n >= min(stages)][dt_n <= max(stages)]
  }
  pps <- split(pps, f = factor(pps$dt_n))

  # processing_along(pps) data ------------------------------------------------
  piit <- lapply(seq_along(pps), function(i) {
    ppsi <- pps[[i]]
    pit <- lapply(unique(ppsi$dtp_n), function(j) {
      sfc <- sf_open_con(sfc = sfc)
      # get function and prepare arguments
      ppsij <- ppsi[dtp_n == j]
      f <- ppsij$f[1]
      fpm <- sf_dta_read(sfc = sfc, tv = "f_params")
      if (!f %in% c("dt_calc", "dt_join", "dt_clean", "dt_drift")) {
        f_params <- fpm[["f_params"]][[ff[[3]][ff[[1]] %in% f][[1]]]][
          ppsid == paste0(ppsi$dt_n[1], "_", j)
        ]
      } else {
        f_params <- as.list(ppsij$f_params)
      }
      if (chunk_v || verbose || xtra_v) {
        cli::cli_h3(c("{station_file}: {ppsi$dt_n[1]}-{j}: {.strong {f}}"))
      }
      # get arguments and process function
      args <- list(station_file = station_file,
        f_params = f_params, ppsij = ppsij, sfc = sfc,
        verbose = verbose, xtra_v = xtra_v, chunk_v = chunk_v,
        dt_format = dt_format, dt_tz = dt_tz
      )
      ppsij_ud <- attempt::attempt(
        expr = do.call(what = f, args = args),
        msg = cli::cli_inform(c("!" = paste0(
          "Error with {station_file}; at {ppsi$dt_n[1]}-{j}: {.strong {f}}"
        )))
      )
      return(ppsij_ud$ppsij)
    })
    pit <- data.table::rbindlist(pit)
    sfc <- sf_open_con(sfc = sfc)

    # convert dt_working to output_dt ----
    odtn <- unique(ppsi$output_dt)[1]

    # append dt_working to chunked file or create new one
    dw <- sf_dta_read(sfc = sfc, tv = "dt_working")
    lapply(dw$dt_working$fs, function(w) {
      sf_dta_chunkr(dta_room = file.path(dirname(sfc)[1], odtn),
        dta_sets = list(readRDS(w)), tn = odtn, chunk_v = chunk_v,
        xtra_v = xtra_v, ri = dw$dt_working$indx$ri,
        rit = dw$dt_working$indx$rit
      )
      # update the log
      lg_tbl <- data.table::data.table(
        tbl_n = odtn,
        rit = dw$dt_working$indx$rit,
        ri = dw$dt_working$indx$ri,
        open = TRUE
      )
      sf_log_update(sfc = sfc, log_update = lg_tbl)
    })
    # write a normal file if not chunked
    if (is.null(dw$dt_working$fs) && length(dw) > 0) {
      dta <- dt_dta_open(dw)
      sl <- sf_dta_wr(dta_room = file.path(dirname(sfc)[1], odtn),
        tn = odtn, dta = dta, verbose = verbose, xtra_v = xtra_v
      )
      sf_log_update(sfc = sfc, log_update = sl)
    }
    sf_dta_rm(sfc = sfc, rm = "dt_working")
    return(pit)
  })
  piit <- data.table::rbindlist(piit)
  opiit <- readRDS(file.path(dirname(sfc[1]), "pipe_seq"))
  piit <- rbind(opiit[!dt_n %in% piit$dt_n], piit)
  piit <- piit[order(dt_n, dtp_n, n)]
  sl <- sf_dta_wr(dta_room = file.path(dirname(sfc[1]), "pipe_seq"),
    dta = pipe_seq, tn = "pipe_seq"
  )
  sf_log_update(sfc = sfc, log_update = sl)
  sfc <- sf_open_con(pipe_house = pipe_house, station_file = station_file)
  unwanted_tbls <- paste0(c(unwanted_tbls, "_hsf_table_"), collapse = "|")
  unwanted_tbls <- names(sfc)[names(sfc) %ilike% unwanted_tbls]
  if (length(unwanted_tbls) == 0) unwanted_tbls <- NULL
  # remove unwanted tables
  sf_dta_rm(sfc = sfc, rm = unwanted_tbls)
  sf_write(pipe_house = pipe_house, station_file = station_file,
    overwrite = TRUE
  )
  return(station_file)
}