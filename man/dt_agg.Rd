% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/h1_dt_agg.R
\name{dt_agg}
\alias{dt_agg}
\title{Aggregate data by a time interval}
\usage{
dt_agg(
  sfc = NULL,
  pipe_house = NULL,
  station_file = NULL,
  f_params = NULL,
  ppsij = NULL,
  gaps = FALSE,
  agg_offset = "0 sec",
  ignore_nas = FALSE,
  gap_tbl = "raw_",
  gaps_phens = NULL,
  verbose = FALSE,
  xtra_v = FALSE,
  chunk_v = FALSE,
  ...
)
}
\arguments{
\item{sfc}{List of file paths to the temporary station-file directory. Generated using \code{ipayipi::sf_open_con()}.}

\item{pipe_house}{Pipeline directory structure generated using \code{ipayipi::ipip_house()}.}

\item{station_file}{The file path of the station being assessed.}

\item{f_params}{Function parameters evaluated by \code{ipayipi::agg_param_eval()}. These are internally parsed to \code{dt_agg()} by \code{dt_process()}.}

\item{ppsij}{Internally parsed by \code{dt_process()}. Table derived from \code{ipayipi::pipe_seq()} showing the summarised function parameters for a data processing step.}

\item{gaps}{Logical. It \code{TRUE} then gaps with their respective unique gap identifiers from the 'gap table' of a station are joined to the aggregated series. These identifiers could be used for further processing.}

\item{agg_offset}{String describing period of offset from the rounded time interval used to aggregate data. For example, if aggregating rainfall data from five minute to daily records, but staggered so that daily rainfall is totalled from 8 am to 8 pm the next day the \code{agg_offset} must be set to \code{"8 hours"}.  When \code{full_eval == TRUE} the function overwrites this parameter in favor of \code{agg_offset} extracted from the partial evaluation.}

\item{ignore_nas}{Logical. If \code{TRUE} then NAs will not be produced in the resulting aggregation. To reflect gaps in data set to \code{FALSE}.}

\item{gap_tbl}{String. Provided to search in the 'gaps' table for a table_name used to described gaps.}

\item{gaps_phens}{Whether to extract gaps pertaining to specific phens. Not fully implemented. Testing functionality.}

\item{verbose}{Logical. Whether or not to report messages and progress.}

\item{xtra_v}{Logical. Whether or not to report xtra messages, progess, plus print data tables.}

\item{chunk_v}{Logical. Extra messaging around data chunking.}
}
\description{
This function aggregates 'ipayipi' formatted data by custom time intervals.
}
\details{
Function has to work within the \code{ipayipi} pipeline as parameters for aggregation are determined during the pipeline evaluation process. The data has to have a column named 'date_time' for aggregation to work. `dt_agg()`` works on both continuous and discontinuous data. When working on discontinuous data, \code{\link[=dt_agg]{dt_agg()}} will aggregate from the first and last available data. Therefore if the logger start or end date-time was before or after this date-time, dummy data should be inserted into the series before aggregation so that the correct start and end date-times are represented.

All recognised variable types, that is, those for which aggregation functions are by default defined in \code{ipayipi::sts_agg_functions}, will be aggregated unless otherwise specified in the aggregation parameters.

Processing is done whilst keeping a minimum amount of data in memory. The station file being worked on is saved in a temporary location so if any errors occur in the processing the original file will not be overwritten.

If an offset on the aggregation is used then the secon value of the offset is added to the 'date_time' stamp for the data.tables 'date_time' value. Aggregation defaults are determined by \code{ipayipi::agg_param_eval()}. Default aggregation functions are determined by the phenomena measure parameter --- see the function for more details.
}
\author{
Paul J. Gordijn
}
