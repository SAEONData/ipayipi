% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/a_ipip_house.R
\name{ipip_house}
\alias{ipip_house}
\title{Build \code{ipayipi} data pipeline housing for a data family}
\usage{
ipip_house(
  pipe_house_dir = ".",
  r = NULL,
  d1_source_room = NULL,
  d2_wait_room = NULL,
  d3_nomvet_room = NULL,
  d4_ipip_room = NULL,
  d5_dta_out = NULL,
  reports = NULL,
  d0_raw_room = NULL,
  work_dir = NULL,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{pipe_house_dir}{An existing base pipeline directory/'room' (or folder) in which all pipeline rooms are 'housed'. \bold{NB!} The \code{pipe_house_dir} directory must be relative to the active console/terminal working directory, or the full path name.
\cr \cr}

\item{r}{Directory for miscellaneous scripts. Within the 'r' room, a sub directory is created called 'pipe_seq' for housing processing pipeline sequence scripts for \code{ipayipi::dt_process()}. Suggestion is to leave \code{NULL} so that this 'room' is nested within the \code{pipe_house_dir}.
The data is moved through an 'ipayipi' pipeline housing system through the following rooms.
\cr \cr
Data moves through an 'ipayipi' pipeline through rooms 1 to 5 outlined below. Along the way raw data is organised and archived, and data is standardised before being processed. \cr}

\item{d1_source_room}{\strong{1}. 'Room' from which raw-data files are imported into the pipeline. If left \code{NULL} a directory named 'd1_source_room' will be created in the pipe_house working directory.}

\item{d2_wait_room}{\strong{2}. Directory into which raw-data moves to from the \code{d1_source_room}. This is also the room where standardisation of raw-data files begins.}

\item{d3_nomvet_room}{\strong{3}. 'Room' into which imbibed, standardised raw-data is stored.}

\item{d4_ipip_room}{\strong{4}. 'Room' where 'station files' are housed. Station files consist of appended, standardised raw-data files---pulled from the \code{d3_nomvet_room}---that have been, or are ready for further processing.}

\item{d5_dta_out}{Directory housing select data products from the pipeline; typically in 'csv' file format.}

\item{reports}{Intended to house 'rmarkdown' reports used for inspection and analysis of data.}

\item{d0_raw_room}{'Room' wherein raw-data files from the \code{d1_source_room} are systematically archived. If this is set to \code{NULL} then raw-data files will not be archived by 'ipayipi'.}

\item{verbose}{Logical. If \code{TRUE} some terminal/console messages may provide useful insight.}
}
\value{
List of pipeline housing 'rooms' (filepaths).
}
\description{
Creates a list of 'rooms', that is, folders/directories, required for an 'ipayipi' data-processing pipeline within an \strong{existing} \code{pipe_house_dir} folder. Suggestion is to use default options: only provide the \code{pipe_house_dir} that must refer to an existing directory for housing your data pipeline. By providing other parameters the directories can be customised for special-use cases.
The recommentation is to build seperate 'pipe_houses' for different data streams or families, for example, separate out automatic weather stations, stand alone rain gauges, and water-level transducers. Whilst the families are housed in different 'pipe houses', iPayipi enables efficient quering and processing of data across different data families.
}
\details{
\subsection{Pipeline directories and data flow}{

This function automates the creation of four/five folders/directories that are requried for bulk processing of files in the ipayipi pipeline structure. The flow of data through an 'ipayipi' pipeline housing system is described below. The preffix to the folders created represents this flow of data.
\enumerate{
\item \emph{pipe_house_dir}*: The main directory within which other directories are housed for preparing, standardising and processing data.
\item \emph{d1_source_room}: The source directory where raw data are harvested from.
\item \emph{d2_wait_room}: A staging directory where 'raw data' are standardised before being transferred/archived in the,
\item \emph{d3_nomvet_room}: Folder housing standardised input data from multiple stations. By appending these standarised files station records (databases) are compiled.
\item \emph{d4_ipip_room}: The directory that compiles standardised data from the \code{d3_nomvet_room} for each station. Station files can be further processed and exported into other formats from here.
\item \emph{d5_dta_out}: Data exports typically generated using \code{ipayipi2csv()}, \code{dta_flat_pull()} or, \code{dta_flat_pull_discnt()}.
\item \emph{d0_raw_room}:  If defined \code{\link[=imbibe_raw_batch]{imbibe_raw_batch()}} can harvest (copy or cut---see funtion documentation) and archive 'raw data' files from the \code{d1_source_room} and will archive them in the \code{d0_raw_room} in monthly folders.
\cr
{*} In older versions of 'ipayipi' the 'pipe_house_dir' argument was named 'work_dir'; this alteration prevents confusion with the R terminal/console working directory.
}
}

\subsection{Pushing data through the pipeline}{

Follow the sequence of functions below for an outline of processing data using ipayipi.
\enumerate{
\item Initiate pipeline housing.
\itemize{
\item \code{\link[=ipip_house]{ipip_house()}}: this function builds a pipe house directory.
}
\item Importing raw data.
\itemize{
\item \code{\link[=logger_data_import_batch]{logger_data_import_batch()}}: to bring in raw data from a source directory.
}
\item Imbibing and standardising raw data.
\itemize{
\item \code{\link[=imbibe_raw_batch]{imbibe_raw_batch()}}: Reads imported data into the pipeline format.
\item \code{\link[=header_sts]{header_sts()}}: For standardising header data, e.g., the station name or title.
\item \code{\link[=phenomena_sts]{phenomena_sts()}}: To get variables or phenomena data and metadata standardised.
\item \code{\link[=transfer_sts]{transfer_sts()}}: Pushes standardised data to an archive for building station files.
}
\item Appending data streams.
\itemize{
\item \code{\link[=append_station_batch]{append_station_batch()}}: Builds station records.
\item \code{\link[=gap_eval_batch]{gap_eval_batch()}}: Clarify & visualize data gaps.
\item \code{\link[=meta_read]{meta_read()}} & \code{\link[=meta_to_station]{meta_to_station()}}: Optional functions to incorporate field or other metadata into station records for further processing.
}
\item Processing data.
In order to process data a sequence of processing stages need to be defined (see \code{?pipe_seq}). Once defined, this sequence gets embedded into respective stations, evaluated and used to process data.
\itemize{
\item \code{\link[=dt_process_batch]{dt_process_batch()}}: To batch process data.
}
\item Querying and visualising data.
There are a few built-in plotting functions utilizing dygraphs, ggplot2, and plotly libraries.
\itemize{
\item \code{\link[=dta_availability]{dta_availability()}}: Check data availability within and across pipelines.
\item \code{\link[=dta_flat_pull]{dta_flat_pull()}}: To harvest continuous data from stations in long or wide formats.
\item \code{\link[=dta_flat_pull_discnt]{dta_flat_pull_discnt()}}: Similar to the above except for discontinuous data.
\item \code{\link[=plot_cumm]{plot_cumm()}}: Visualise cummulative response of phenomena.
\item \code{\link[=plot_bar_agg]{plot_bar_agg()}}, \code{\link[=plotdy_drift]{plotdy_drift()}}, \code{\link[=plot_cleanr]{plot_cleanr()}}, and \code{\link[=plot_m_anomaly]{plot_m_anomaly()}} are more plotting functions.
\item Various plotting functions to examine/cross-examine data.
}
}
}
}
\examples{
# Inititate default pipeline in current working directory ----
pd <- "." # define the working directory
# assign pipeline directory list to `pipe_house`
pipe_house <- ipip_house(pipe_house_dir = pd)
print(pipe_house) # print the pipe_house object

# Set the `d0_raw_room` to NULL -- this will prevent archiving
# of raw data in the `d0_raw_room`. Note that this can only be set to NULL
# after running the line of code above.
pipe_house$d0_raw_room <- NULL

# Attemp to create pipe house directory in random folder
# Note the message that the line below produces when the random directory
# does not exist.
ipip_house(pipe_house_dir = "rand_dir_doesnt_exist", verbose = TRUE)

# Create a custom 'd1_source_room' called 'dta_in'
sr <- "dta_in"
pipe_house <- ipip_house(pipe_house_dir = pd, d1_source_room = sr)
print(pipe_house)
# Note how in the last example, now the source room is at "./dta_in"

}
\author{
Paul J. Gordijn
}
\keyword{creation,}
\keyword{directory}
\keyword{folder}
\keyword{initiate}
\keyword{pipeline,}
\keyword{structure}
