% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/z_sub_a_imbibe_raw_flat.R
\name{imbibe_raw_flat}
\alias{imbibe_raw_flat}
\title{Imbibes logger data exports}
\usage{
imbibe_raw_flat(
  file_path = NULL,
  file_ext = NULL,
  col_dlm = NULL,
  dt_format = c("Ymd HMOS", "Ymd HMS", "Ymd IMOSp", "Ymd IMSp", "ymd HMOS", "ymd HMS",
    "ymd IMOSp", "ymd IMSp", "mdY HMOS", "mdY HMS", "mdy HMOS", "mdy HMS", "mdy IMOSp",
    "mdy IMSp", "dmY HMOS", "dmY HMS", "dmy IMOSp", "dmy IMSp"),
  dt_tz = "Africa/Johannesburg",
  data_setup = NULL,
  verbose = FALSE,
  xtra_v = FALSE,
  ...
)
}
\arguments{
\item{file_path}{Path and name of file (excluding the file extension).}

\item{file_ext}{The file extension defaults of the raw logger data files. This can be left as \code{NULL} so 'all' files but those with extensions that cannot be imbibed (".ipr|.ipi|.iph|.xls|.rps|.rns|.ods|.doc").}

\item{col_dlm}{The column delimter which is fed to \code{data.table::fread()}. Defaults to NULL. When \code{NULL} the function uses \code{data.table::fread} ability to 'guess' the delimeter.}

\item{dt_format}{The function attempts to work out the date-time format from a vector of format types supplied to this argument. The testing is done via \code{lubridate::parse_date_time()}. \code{lubridate::parse_date_time()} prioritizes the tesing of date-time formats in the order vector of
formats supplied. The default vector of date-time formats supplied should work well for most logger outputs.}

\item{dt_tz}{Recognized time-zone (character string) of the data locale. The default for the package is South African, i.e., "Africa/Johannesburg" which is equivalent to "SAST".}

\item{data_setup}{List of options used to extract data and metadata from instrument data outputs. Mandatory fields are indicated with an '*'.
File header options include\eqn{*^1}:
\enumerate{
\item *\strong{file_format} -- the native/raw file format.
\item *\strong{station_title} -- the supplied instrument station title \eqn{*^2}.
\item location -- the standardised location (name) of the station.
\item *\strong{logger_type} -- the type of logger.
\item *\strong{logger_sn} -- the serial number of the logger.
\item logger_os -- the operating system (or firmware version) on the logger.
\item logger_program_name -- the name of the program installed on the logger
(also 'DLD name' on Cambel Scientific systems).
\item logger_programe_sig -- signature of the logger program (also 'DLD
signature' on Cambel Scientific systems).
\item logger_title -- the custom name given to a logger by the programmer.
\item table_name -- the generic name of the table containing data.
}

\eqn{*^1} These options must be supplied as a charater string or the row and column index provided as for example, rici(ri = 1, ci = 2). See \code{?ipayipi::rici()} for more details.
\eqn{*^2} If this option is supplied as "!fp!" the \code{station_title} will extracted from the base name of the file path with digits, and leading/training white spaces and underscores removed. Note digits (integers) are only replaced when there are more than three in the string---to remove date-time information from the title.
\enumerate{
\item *\strong{date_time} -- Only the column index must be provided here as an integer, e.g., 3. If the date and time are serperated in different columns, columns must be provided in a logical order as these are concatenated in the provided order.
\item dttm_inc_exc -- Logical vector of length two. Defaults to \code{c(TRUE, FALSE)}. Used to define inclusive or exclusvie time intervals, and whether to change these (see the details section for more).
}

File phenomena information and data \eqn{*^3}:
\enumerate{
\item *\strong{phen_name} -- a list of row and column numbers corresponding to the names of phenomena (variables).
\item phen_unit -- a list of row and column numbers corresponding to the names of phenomena units.
\item phen_var_type -- a vector of character strings designating the type of variable for each phenomenon.
\item phen_measure -- a list of row and column numbers corresponding to the type of measurement calculated by the logger for each phenomena, e.g., an 'average', 'sample', 'minimum', etc.
\item phen_offset -- a list of offset values that have been pre-applied to the data, i.e, the offset is only noted and not used to transform the data.
\item sensor_id -- a list of row and column numbers corresponding to sensor unique id values. Otherwise a vector of character strings designating the type of 'sensor_id' for each phenomenon.
}

\eqn{*^3} These options must be supplied as using \code{ipayipi::rng_rici()}, or input as a vector of character strings with the actual values. If using     \code{ipayipi::rng_rici()}, at least the row in which phenomena details are found and the columns wherein these lie are required. See ?ipayipi::rng_rici() for more details.
\enumerate{
\item *\strong{data_row} -- a single integer value designating the row where phenomena data begin from.
\item id_col -- a single integer value designating a data row unique identifier row.
}

NB! Note that for Solonist xle files there is a prebuilt 'data_setup' \code{ipayipi::solonist}. If the \code{file_path} is for an 'xle' file, and \code{data_setup} is null, then this default data_setup will be used.}

\item{verbose}{Logical passed to \code{attempt::attempt()} which reads the logger text file in with either \code{data.table::fread()} or base R. Also whether to print progress.}

\item{pipe_house}{List of pipeline directories. \strong{See} \code{ipayipi::ipip_house()} \strong{for details}.}

\item{record_interval_type}{If there are is no discrete record interval set in the logger program, i.e., the sampling is event-based, then this parameter must be set to "event_based". By default this function has this parameter set to "continuous", but the record interval is scrutinized by 'ipayipi::record_interval_eval()' --- see the help files for this function for more information.
The parameter supplied here is only used if there is only one data record and the record interval cannot be evaluated by \code{ipayipi::record_interval_eval()}.}

\item{remove_prompt}{Logical; passed to \code{ipayipi::record_interval_eval()}. Activate a readline prompt to choose whether or not filter our records from \code{dta_in} with inconsistent record intervals.}

\item{logg_interfere_type}{Two options here: "remote" or "on_site". Each time a logger is visited is counted as a logger interference event. Type \emph{'remote'} occurs when data is downloaded remotely. Type \emph{'on_site'} is when data was downloaded on site. \emph{See details} ...}
}
\value{
A list of class "ipayipi_raw_data" that contains a 'data_summary', 'phens' (phenomena), and 'raw_data' tables (data.table).
}
\description{
Function to read in 'flat' loggers files into R. A first step towards processing data in \code{ipayipi}.
}
\details{
This function uses \code{data.table::fread} which is optimized for processing 'big data'. Apart from usual the usual options which can be parsed to \code{data.table::fread} this function generates some standardised metadata to complement the read from a logger data table (if \code{data.table::fread()} is unsuccessful \code{base::read.csv()} is used). This metadata may vary from one logger output to another. To cater for this variation this function requires a \code{data_setup} to be completed. Once setup this can be used as a standard for further imports.
This function also attempts to check whether the recording interval in the data date-time stamp has been consistent. A prompt is called if there are inconsistent time intervals between record events, and data rows with inconsistent time intervals will be removed if approved.
A basic check is performed to check the success of converting date-time values to a recognised format in R (i.e., POSIXct).
Regarding the \code{logg_interfere_type} parameter. Owing to potential interference of sensors etc when downloading data 'on site' or logger related issues when data is sent/obtained remotely, the date-time stamps of these events must be preserved. A \code{logg_interfere} data table is generated for this purpose and stored with the data. This data cannot necessarily be extracted from the 'data_summary' once data has been appended as some of this data will be overwritten during the appending process. The purpose of the 'logg_interfere' table is to retain this information, which is used by \code{ipayipi} for further processing.
Regarding the \code{dttm_inc_exc}, vector of length two. The \emph{first} logical element indicates whether the date-time of raw-continuous data represents the starting or ending date-time of the recording interval. General convention (ISO 8601 standard) states that a time-interval measurements begins from point zero, and therefore, the starting timestamp captures all future recordings until the next timestamp. Therefore, all measurements on day one, include all measurements/scans until just before day two, i.e., from 1.000 to 1.999, as a simple example (limited to 4 significant figures). This can be written as [1.000,2.000), and is also known as the half-open approach. The \emph{second} logical element indicates whether the reverse of the first supplied argument must be applied, i.e., should the half-open be converted to (]---exclusive of the first teimstamp and exclusive of the last. Cambell Scientific loggers often use an the (] approach that can be converted to [) by supplying \code{c(FALSE, TRUE)} to the \code{dttm_inc_exc} parameter, Defaults to \code{c(TRUE, FALSE)}.

[1.000,2.000), and is also known as the half-open approach. The \emph{second} logical element indicates whether the reverse of the first supplied argument must be applied, i.e., should the half-open be converted to (]: R:1.000,2.000),\%20and\%20is\%20also\%20known\%20as\%20the\%20half-open\%20approach.\%20The\%20_second_\%20logical\%20element\%20indicates\%20whether\%20the\%20reverse\%20of\%20the\%20first\%20supplied\%20argument\%20must\%20be\%20applied,\%20i.e.,\%20should\%20the\%20half-open\%20be\%20converted\%20to\%20(
}
\author{
Paul J. Gordijn
}
